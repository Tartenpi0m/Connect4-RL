{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AgentDQNv1 import AgentDQNv1\n",
    "from AgentDQNv2 import AgentDQNv2\n",
    "from AgentDQNv3 import AgentDQNv3\n",
    "from CounterAgent import CounterAgent\n",
    "\n",
    "from envP4 import Connect4Env\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load QValue/Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "qvalue1 = \"Linear_Random_v3/20000_a1.pt\"\n",
    "qvalue2 = \"Linear_Random_v3/20000_a2.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play One-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent1 1\n",
      "\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\n",
      "\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\n",
      "\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\n",
      "\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\n",
      "\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\n",
      "\u001b[37m. \u001b[39m\u001b[31mX \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\u001b[37m. \u001b[39m\n",
      "\n",
      "\n",
      "[[0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#step\n",
    "if first:\n",
    "    \n",
    "    player = 1\n",
    "    winner = 0 #False\n",
    "\n",
    "    env = Connect4Env()\n",
    "    state = env.reset()\n",
    "    agent = AgentDQNv2(1, env.action_space, env.observation_space, lr=0, eps_init=0, eps_step=0, name=\"player 1\")\n",
    "    agent2 = CounterAgent(2, env.action_space, env.observation_space, lr=0, eps_init=0, eps_step=0, name=\"player 2\")\n",
    "    # agent.q_values = torch.load(\"./runs/\" + qvalue1)\n",
    "    # agent2.q_values = torch.load(\"./runs/\" + qvalue2)\n",
    "    first = False\n",
    "#try:\n",
    "if not winner:\n",
    "    if player == 1:\n",
    "        action = agent.get_action(state, env.get_moves())\n",
    "        print('agent1',action)\n",
    "        state, reward, winner, info = env.step(action, player)\n",
    "        player = 2\n",
    "    elif player == 2:\n",
    "        print(\"COUNTER\")\n",
    "        action = agent2.get_action(state, env.get_moves())\n",
    "        print('agent2',action)\n",
    "        state, reward, winner, info = env.step(action, player)\n",
    "        player = 1\n",
    "\n",
    "    env.render()\n",
    "\n",
    "    if winner:\n",
    "        print(\"THE WINNER IS PLAYER\", winner)\n",
    "        first = True\n",
    "        winner = 0 #False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_board_state = [[0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0],[0 ,0 ,0, 0, 0, 0],[0, 0, 0, 0, 0, 0],[0, 0 ,0, 0, 0, 0],[0, 0, 0, 0, 0 ,0],[0, 0 ,0 ,0, 0, 0]]\n",
    "board_state      = [[0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0],[0 ,0 ,0, 0, 0, 0],[2, 0, 0, 0, 0, 0],[0, 0 ,0, 0, 0, 0],[0, 0, 0, 0, 0 ,0],[0, 0 ,0 ,0, 0, 0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import numpy as np\\n\\ndef agent_move(board_state, prev_board_state):\\n    # Convert input to NumPy arrays\\n    board_state = np.array(board_state)\\n    prev_board_state = np.array(prev_board_state)\\n    \\n    # Find the column where the opponent played\\n    diff = board_state - prev_board_state\\n    nonzero_idx = np.where(diff != 0)    \\n    if len(nonzero_idx[1]) > 0:\\n        opponent_last_move = (nonzero_idx[0][0],nonzero_idx[1][0])\\n    else:\\n        # If the difference is all zeros, assume opponent didn't make a move\\n        opponent_last_move = (-1,-1)\\n    \\n    action = opponent_last_move[0]\\n    return action \\n\\n    # Find the first empty cell in the column\\n    #col = opponent_last_move[0]\\n    #for row in range(0,board_state.shape[1]-1, 1):\\n        #if col >= 0 and board_state[col][row] == 0:\\n            #return (col,row)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "\n",
    "def agent_move(board_state, prev_board_state):\n",
    "    # Convert input to NumPy arrays\n",
    "    board_state = np.array(board_state)\n",
    "    prev_board_state = np.array(prev_board_state)\n",
    "    \n",
    "    # Find the column where the opponent played\n",
    "    diff = board_state - prev_board_state\n",
    "    nonzero_idx = np.where(diff != 0)    \n",
    "    if len(nonzero_idx[1]) > 0:\n",
    "        opponent_last_move = (nonzero_idx[0][0],nonzero_idx[1][0])\n",
    "    else:\n",
    "        # If the difference is all zeros, assume opponent didn't make a move\n",
    "        opponent_last_move = (-1,-1)\n",
    "    \n",
    "    action = opponent_last_move[0]\n",
    "    return action \n",
    "\n",
    "    # Find the first empty cell in the column\n",
    "    #col = opponent_last_move[0]\n",
    "    #for row in range(0,board_state.shape[1]-1, 1):\n",
    "        #if col >= 0 and board_state[col][row] == 0:\n",
    "            #return (col,row)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'agent_move(board_state, prev_board_state)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"agent_move(board_state, prev_board_state)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[0 for j in range(6)] for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
